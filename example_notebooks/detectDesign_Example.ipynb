{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters\n",
    "\n",
    "# Load in target genome\n",
    "Find potential binding sites\n",
    "Add in gene information if provided\n",
    "\n",
    "# Load in off-target genomes\n",
    "Find potential binding sites\n",
    "Add in gene information if provided\n",
    "\n",
    "# Loop through regions\n",
    "Set target region names and output folders\n",
    "\n",
    "Find on-target sgRNA pairs\n",
    " If there are no candidate pairs continue\n",
    " \n",
    "Find off-targets for individual sgRNA for all genomes\n",
    "  \n",
    " Find proximal off-targets for all genomes\n",
    "\n",
    "Create summary plots\n",
    " Full_Mism paired summary\n",
    " Seed_Mism paired summary\n",
    " Proximal paired summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from detectDesign import *\n",
    "from itertools import repeat\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('tableau-colorblind10')\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.float_format = '{:,.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Target Pair parameters =======\n",
    "PAIR_SHARE_STRAND = True # Checks if the pairs are on the same strand\n",
    "\n",
    "# ======= Off-target parameters =======\n",
    "# Set individual off-target specficiations\n",
    "HAMMING_MAX = 20\n",
    "SEED_SIZE = 8\n",
    "\n",
    "# Set proximal off-target range\n",
    "PROXIMAL_FULL = 0\n",
    "PROXIMAL_SEED = 0\n",
    "PROXIMAL_MIN = 23\n",
    "PROXIMAL_MAX = 200\n",
    "\n",
    "STRONG_FULL = 5\n",
    "STRONG_SEED = 0\n",
    "\n",
    "SMALLSEED_FULL = 0\n",
    "SMALLSEED_MAX = 0\n",
    "SMALLSEED_SIZE = 5\n",
    "\n",
    "# ======= Output details =======\n",
    "DATE = '02132020'\n",
    "TARGET_CSV = True\n",
    "OFF_TARGET_CSV = True\n",
    "previous_genome_folder = ''\n",
    "total_candidate_table = []\n",
    "target_col = 'Target_Guide'\n",
    "full_col = 'Full_Mism'\n",
    "seed_col = 'Seed_Mism'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import target genomes, names, and regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_INPUT_FILE = './detectDesign_input.csv'\n",
    "target_input = pd.read_csv(TARGET_INPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_Genome</th>\n",
       "      <th>Genome_Name</th>\n",
       "      <th>Target_Name</th>\n",
       "      <th>Range</th>\n",
       "      <th>Offtarget_Folder</th>\n",
       "      <th>Pair_Dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>./genomes/ontargets/Ftula_LVS_genomic.fa</td>\n",
       "      <td>F_tula</td>\n",
       "      <td>F.TN</td>\n",
       "      <td>[678,1078]</td>\n",
       "      <td>./genomes/offtargets/</td>\n",
       "      <td>[58,66]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>./genomes/ontargets/Ftula_LVS_genomic.fa</td>\n",
       "      <td>F_tula</td>\n",
       "      <td>F.TNH</td>\n",
       "      <td>[436394,436794]</td>\n",
       "      <td>./genomes/offtargets/</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Target_Genome Genome_Name Target_Name  \\\n",
       "0  ./genomes/ontargets/Ftula_LVS_genomic.fa      F_tula        F.TN   \n",
       "1  ./genomes/ontargets/Ftula_LVS_genomic.fa      F_tula       F.TNH   \n",
       "\n",
       "             Range       Offtarget_Folder Pair_Dist  \n",
       "0       [678,1078]  ./genomes/offtargets/   [58,66]  \n",
       "1  [436394,436794]  ./genomes/offtargets/        62  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./genomes/ontargets/Ftula_LVS_genomic.fa\n",
      "./genomes/ontargets/Ftula_LVS_genomic.fa F_tula F.TN [678,1078] ./genomes/offtargets/\n",
      "F.TN\n",
      "F.TN B_sub\n",
      "Empty proximal counts 8 seed in B_sub\n",
      "F.TN F_tula\n",
      "./genomes/ontargets/Ftula_LVS_genomic.fa F_tula F.TNH [436394,436794] ./genomes/offtargets/\n",
      "F.TNH\n",
      "F.TNH B_sub\n",
      "Empty proximal counts 8 seed in B_sub\n",
      "F.TNH F_tula\n"
     ]
    }
   ],
   "source": [
    "for curr_target_file in set(target_input['Target_Genome']):\n",
    "    print(curr_target_file)\n",
    "    \n",
    "    # Load in target genome\n",
    "    target_pd = target_input[target_input['Target_Genome'] == curr_target_file].reset_index()\n",
    "    TARGET_NAME = target_pd['Genome_Name'][0]\n",
    "    \n",
    "    if curr_target_file.endswith('.csv') == True:\n",
    "        target_sites = pd.read_csv(curr_target_file, index_col=0)\n",
    "    else:\n",
    "        target_seq = read_seq_file(curr_target_file)\n",
    "        target_sites = find_guides_multiple_pams(target_seq, TARGET_NAME, ['NGG'])\n",
    "\n",
    "\n",
    "    for i, row in target_pd.iterrows():\n",
    "        curr_target_genome, curr_target_name, curr_name, curr_range, curr_offtarget_folder, curr_pair_range = row[1], row[2], row[3], row[4], row[5], row[6]\n",
    "        print(curr_target_genome, curr_target_name, curr_name, curr_range, curr_offtarget_folder)\n",
    "    \n",
    "        # Load in off-target genome(s)\n",
    "        if previous_genome_folder != curr_offtarget_folder:\n",
    "\n",
    "            offtarget_sites_list = [] \n",
    "            for curr_file in iglob(curr_offtarget_folder + '*'):\n",
    "                curr_offtarget_name = curr_file.split('/')[-1].split('.')[-2]\n",
    "                if curr_file.endswith('.csv') == True:\n",
    "                    offtarget_sites = pd.read_csv(curr_file, index_col=0)\n",
    "                else:\n",
    "                    offtarget_seq = read_seq_file(curr_file)\n",
    "                    offtarget_sites = find_guides_multiple_pams(offtarget_seq, curr_offtarget_name, ['NGG'])\n",
    "                offtarget_sites_list.append(offtarget_sites)\n",
    "\n",
    "            # Combine offtarget genome sites into one file\n",
    "            offtarget_genome_sites_pd = pd.concat(offtarget_sites_list, sort=True)\n",
    "\n",
    "            # Save name of loaded genome folder to save computation\n",
    "            previous_genome_folder = curr_offtarget_folder\n",
    "        \n",
    "        print(curr_name)\n",
    "        # Set target region names and output folders\n",
    "        if curr_range == '':\n",
    "            TARGET_REGION = False\n",
    "        else:\n",
    "            TARGET_REGION = literal_eval(curr_range)\n",
    "        \n",
    "        OUTPUT_FOLDER = './results/F_tularensis/' + DATE + '_' + curr_name +'_targets/'\n",
    "        PREFIX = OUTPUT_FOLDER + TARGET_NAME\n",
    "        AUX_FOLDER = OUTPUT_FOLDER + '/aux/'\n",
    "        AUX_PREFIX = AUX_FOLDER + TARGET_NAME\n",
    "        COUNTS_OUTFILE = AUX_PREFIX + '_offtargets_indv_summary_' + DATE + '.csv'\n",
    "        COUNTS_PAIR_OUTFILE = AUX_PREFIX + '_offtargets_pair_summary_' + DATE + '.csv'\n",
    "        COUNTS_PAIR_SUMMARY_OUTFILE = PREFIX + '_offtargets_summary_' + DATE + '.csv'\n",
    "        PROXIMAL_OUTFILE = AUX_PREFIX + '_offtargets_proximal_fullmism' + str(PROXIMAL_FULL) + '_seedlen' + str(SEED_SIZE) + '_seedmism_' + str(PROXIMAL_SEED) + '_' + DATE + '.csv'\n",
    "        PROXIMAL_SMALLSEED_OUTFILE = AUX_PREFIX + '_offtargets_smallseed_proximal_fullmism' + str(SMALLSEED_FULL) + '_seedlen' + str(SMALLSEED_SIZE) + '_seedmism_' + str(SMALLSEED_MAX) + '_' + DATE + '.csv'\n",
    "        FIGURE_OUTFILE = AUX_PREFIX + '_pair_summary_' + DATE + '.png'\n",
    "        FIGURE_SEED_OUTFILE = AUX_PREFIX + '_seed_pair_summary_' + DATE + '.png'\n",
    "\n",
    "        # Create output folder if it doesn't exist\n",
    "        if not os.path.exists(AUX_FOLDER):\n",
    "            os.makedirs(AUX_FOLDER)\n",
    "\n",
    "        \n",
    "        curr_pair_range = literal_eval(curr_pair_range)\n",
    "        if isinstance(curr_pair_range, int):\n",
    "            PAIR_EXACT = True # When True target pairs filter distance between MIN_DIST and MAX_DIST instead of exact PAIR_DIST\n",
    "            PAIR_DIST = curr_pair_range # Exact distance for target pair\n",
    "        else:\n",
    "            # Select range of distances, only if PAIR_EXACT == False\n",
    "            PAIR_EXACT = False\n",
    "            PAIR_DIST = 0\n",
    "            MIN_DIST, MAX_DIST = curr_pair_range\n",
    "        \n",
    "        \n",
    "        # Find all on-target sgRNA pairs\n",
    "        target_sites_region = target_sites[target_sites['Start'].between(TARGET_REGION[0], TARGET_REGION[1])]\n",
    "        candidate_table = find_target_pairs(target_sites_region, TARGET_NAME, MAX_DIST, MIN_DIST, PAIR_EXACT, PAIR_DIST, TARGET_REGION, PAIR_SHARE_STRAND, TARGET_CSV, AUX_FOLDER)\n",
    "            # If there are no candidate pairs continue\n",
    "        if len(candidate_table) == 0:\n",
    "            print('No candidate pairs in ' + str(curr_name))\n",
    "            continue\n",
    "\n",
    "        # Find off-targets for individual sgRNA for all genomes\n",
    "        split_candidates = split_pairs(candidate_table)\n",
    "        offtargets_total_pd = find_hamming(offtarget_genome_sites_pd, split_candidates.drop_duplicates('Guide'), HAMMING_MAX, SEED_SIZE, SEED_SIZE)\n",
    "        offtargets_total_pd = offtargets_total_pd.merge(split_candidates[['Guide', 'index']], left_on='Target_Guide', right_on='Guide')\n",
    "        offtargets_total_pd = offtargets_total_pd.rename(columns={'Guide_x': 'Guide', 'index': 'Pair_idx'})\n",
    "\n",
    "        # Create summary counts\n",
    "        # Get individual counts\n",
    "        counts_pd = get_mism_counts(offtargets_total_pd, target_col, full_col, seed_col)\n",
    "\n",
    "        # Get and sort the counts for on-target paired output and plots\n",
    "        counts_pd = expand_list_to_cols(counts_pd, 'Seed_Mism', nan=0, fix_int=True)\n",
    "        counts_pd = expand_list_to_cols(counts_pd, 'Full_Mism', nan=0, fix_int=True)\n",
    "\n",
    "        # Find the columns for our given dataframe and sort it by name and number \n",
    "        n = pd.DataFrame(counts_pd.columns[5:], columns=['Name'])\n",
    "        n['Pre']= n['Name'].apply(lambda x: str(x).split('Mism')[0])\n",
    "        n['Num']= n['Name'].apply(lambda x: int(str(x).split('Mism')[1]))\n",
    "        sorted_columns = list(counts_pd.columns[0:3]) + list(n.sort_values(['Pre', 'Num'], ascending=[False, True])['Name'])\n",
    "        counts_pd = counts_pd[sorted_columns]\n",
    "        counts_pd.to_csv(COUNTS_OUTFILE)\n",
    "\n",
    "        x = counts_pd.groupby(['Pair_idx', 'Genome']).sum()\n",
    "        y = counts_pd.groupby(['Pair_idx', 'Genome'])['Guide'].apply(lambda x: list(x.drop_duplicates()))\n",
    "        pair_table_pd = pd.concat([y.apply(lambda x: x[0]).rename('Guide1'),\n",
    "                                   y.apply(lambda x: x[1]).rename('Guide2'),\n",
    "                                   x], axis=1).reset_index()\n",
    "        pair_table_pd = pair_table_pd[sorted_columns[0:2] + ['Guide1', 'Guide2'] + sorted_columns[3:]]\n",
    "        pair_table_pd.to_csv(COUNTS_PAIR_OUTFILE)\n",
    "\n",
    "        # Full_Mism and Seed_Mism paired summary plots\n",
    "        pair_counts_pd = pair_table_pd.reset_index() # Reset index to undo grouping\n",
    "\n",
    "        # Plot Full_Mism and Seed_Mism count plots for on-target pairs in each genome\n",
    "        for curr_genome in set(pair_counts_pd['Genome']):\n",
    "            curr_pair_counts_pd = pair_counts_pd[pair_counts_pd['Genome'] == curr_genome]\n",
    "            for plot_col in ['Full_Mism', 'Seed_Mism']:\n",
    "                filter_col = [col for col in sorted_columns if str(col).startswith(plot_col)]\n",
    "                split_num = [x.split('Mism')[-1] for x in filter_col]\n",
    "                zipped_data = zip_values(curr_pair_counts_pd[filter_col], 0, split_num)\n",
    "                curr_FIG_OUTFILE = AUX_FOLDER + plot_col + '_summary_' + str(curr_genome) + '_' + DATE + '.png'\n",
    "                side_by_side_bar(zipped_data, curr_pair_counts_pd['Pair_idx'], \n",
    "                                 ticks=range(int(split_num[-1])+1), space=0.15)\n",
    "                plt.title(plot_col + ' in ' + curr_genome)\n",
    "                plt.ylabel('Counts')\n",
    "                plt.xlabel(plot_col)\n",
    "                plt.savefig(curr_FIG_OUTFILE, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Find off-targets filtered for pair prep\n",
    "        total_proximal_pd = find_proximal_perpair(offtargets_total_pd[offtargets_total_pd['Seed_Mism'].le(0)], PROXIMAL_MAX, PROXIMAL_MIN)\n",
    "        cols_for_drop = total_proximal_pd.columns[[('One_Hot' in x) or ('Unnamed' in x) or ('_y_' in x) for x in total_proximal_pd.columns]]\n",
    "        total_proximal_pd = total_proximal_pd.drop(columns=cols_for_drop)\n",
    "        total_proximal_pd = total_proximal_pd.drop_duplicates()\n",
    "        total_proximal_pd.to_csv(PROXIMAL_OUTFILE)\n",
    "\n",
    "        # Create proximal summary counts\n",
    "        # Get the individual sgRNA proximal counts\n",
    "        # Get and sort the proximal counts for on-target paired sgRNA output and plots\n",
    "        # Small seed calculations\n",
    "        offtargets_smallseed_total_pd = find_hamming(offtarget_genome_sites_pd.drop(columns=['Seed_One_Hot']), split_candidates.drop_duplicates('Guide'), HAMMING_MAX, SMALLSEED_MAX, SMALLSEED_SIZE)\n",
    "        offtargets_smallseed_total_pd = offtargets_smallseed_total_pd.merge(split_candidates[['Guide', 'index']], left_on='Target_Guide', right_on='Guide')\n",
    "        offtargets_smallseed_total_pd = offtargets_smallseed_total_pd.rename(columns={'Guide_x': 'Guide', 'index': 'Pair_idx'})\n",
    "        total_smallseed_proximal_pd = find_proximal_perpair(offtargets_smallseed_total_pd[offtargets_smallseed_total_pd['Seed_Mism'].le(0)], PROXIMAL_MAX, PROXIMAL_MIN)\n",
    "        cols_for_drop = total_smallseed_proximal_pd.columns[[('One_Hot' in x) or ('Unnamed' in x) or ('_y_' in x) for x in total_smallseed_proximal_pd.columns]]\n",
    "        total_smallseed_proximal_pd = total_smallseed_proximal_pd.drop(columns=cols_for_drop)\n",
    "        total_smallseed_proximal_pd = total_smallseed_proximal_pd.drop_duplicates()\n",
    "        total_smallseed_proximal_pd.to_csv(PROXIMAL_SMALLSEED_OUTFILE)\n",
    "\n",
    "        if len(total_smallseed_proximal_pd) > 0:\n",
    "            for curr_genome in set(total_smallseed_proximal_pd['Genome_1']):        \n",
    "                print(curr_name, curr_genome)\n",
    "                curr_total_smallseed_proximal_pd = total_smallseed_proximal_pd[total_smallseed_proximal_pd['Genome_1'] == curr_genome]\n",
    "\n",
    "                # If any, plot the small seed proximal matches\n",
    "                if len(curr_total_smallseed_proximal_pd) > 0:\n",
    "                    # Fill any missing data with zeros, carry through filled data\n",
    "                    s = curr_total_smallseed_proximal_pd.groupby(['Pair_idx_1'])\n",
    "                    objects = list(s.groups.keys())\n",
    "                    data_s_pd = s.count()[['Start_1']].reset_index()\n",
    "                    fill_zeros_s = set(objects) - set(curr_total_smallseed_proximal_pd['Pair_idx_1'])\n",
    "                    zeros_s_pd = pd.DataFrame(list(zip(fill_zeros_s, [0]*len(fill_zeros_s))), columns=['Pair_idx_1', 'Start_1'])\n",
    "                    data_s_pd = data_s_pd.append(zeros_s_pd).sort_values('Pair_idx_1')\n",
    "                    data_s = list(data_s_pd['Start_1']) # Save ordered and filled data\n",
    "                    s_pos = np.arange(len(objects))\n",
    "                    plt.bar(s_pos, data_s, align='center', alpha=0.75)\n",
    "                    name_s = '\\n Proximal perfect seed counts per pair in ' + str(curr_genome) + ' for ' + str(curr_name) + '\\n Seed '+ str(SMALLSEED_SIZE) + 'bp match: ' + str(SMALLSEED_MAX) + ', Dist: [' + str(PROXIMAL_MIN) + ',' + str(PROXIMAL_MAX) + ']'\n",
    "                else:\n",
    "                    print('Empty proximal counts, small seed ' + str(SMALLSEED_SIZE) + ' in ' + str(curr_genome))\n",
    "                    continue\n",
    "\n",
    "                # If any, plot the large seed proximal matches\n",
    "                if len(total_proximal_pd) > 0:\n",
    "                    curr_total_proximal_pd = total_proximal_pd[total_proximal_pd['Genome_1'] == curr_genome]\n",
    "                    if len(curr_total_proximal_pd) > 0:\n",
    "                        # Fill any missing data with zeros, carry through filled data\n",
    "                        y = curr_total_proximal_pd.groupby(['Pair_idx_1'])\n",
    "                        data_y_pd = y.count()[['Start_1']].reset_index()\n",
    "                        fill_zeros = set(objects) - set(curr_total_proximal_pd['Pair_idx_1'])\n",
    "                        zeros_pd = pd.DataFrame(list(zip(fill_zeros, [0]*len(fill_zeros))), columns=['Pair_idx_1', 'Start_1'])\n",
    "                        data_y_pd = data_y_pd.append(zeros_pd).sort_values('Pair_idx_1')\n",
    "                        data_y = list(data_y_pd['Start_1']) # Save ordered and filled data\n",
    "                        plt.bar(s_pos, data_y, align='center', alpha=0.75)\n",
    "                    else:\n",
    "                        print('Empty proximal counts ' + str(SEED_SIZE) + ' seed in ' + str(curr_genome))\n",
    "                else:\n",
    "                    print('Empty proximal counts ' + str(SEED_SIZE) + ' seed in ' + str(curr_genome))\n",
    "\n",
    "                plt.xticks(s_pos, objects)\n",
    "                plt.ylabel('Counts')\n",
    "                plt.xlabel('Pair idx')\n",
    "                name_y = '\\n Seed '+ str(SEED_SIZE) + 'bp match: ' + str(PROXIMAL_SEED) + ', Dist: [' + str(PROXIMAL_MIN) + ',' + str(PROXIMAL_MAX) + ']' \n",
    "                plt.title(name_s + name_y)\n",
    "                plt.legend([str(SMALLSEED_SIZE) + 'bp seed', str(SEED_SIZE) + 'bp seed'])\n",
    "\n",
    "                curr_FIG_OUTFILE = OUTPUT_FOLDER + 'proximal_summary_' + str(curr_genome) + '_' + DATE + '.png'\n",
    "                plt.savefig(curr_FIG_OUTFILE, bbox_inches='tight')\n",
    "                plt.close()\n",
    "        else:\n",
    "            print('No off-target proximal pairs with ' + str(SMALLSEED_SIZE) + ' seed in ' + str(curr_name))\n",
    "\n",
    "\n",
    "        count_fullseed = 'Prox_' + str(SEED_SIZE) + 'Seed'\n",
    "        count_smallseed = 'Prox_' + str(SMALLSEED_SIZE) + 'Seed'\n",
    "        counts_ss = total_smallseed_proximal_pd.groupby(['Pair_idx_1', 'Genome_1']).count()['Start_1'].reset_index()\n",
    "        counts_ss.columns = ['Pair_idx', 'Genome', count_smallseed]\n",
    "        counts = total_proximal_pd.groupby(['Pair_idx_1', 'Genome_1']).count()['Start_1'].reset_index()\n",
    "        counts.columns = ['Pair_idx', 'Genome', count_fullseed]\n",
    "        pair_table_pd = pd.merge(pair_table_pd, counts_ss, on=['Pair_idx', 'Genome'], how='left')\n",
    "        pair_table_pd = pd.merge(pair_table_pd, counts, on=['Pair_idx', 'Genome'], how='left')\n",
    "\n",
    "        counts_total_cols = ['Pair_idx', 'Genome', 'Guide1', 'Guide2', count_smallseed, count_fullseed,\n",
    "                             'Seed_Mism0', 'Seed_Mism1', 'Seed_Mism2'] \n",
    "        counts_total_cols = counts_total_cols + list(n[n['Pre'] == 'Full_'].sort_values(['Pre', 'Num'], ascending=[False, True])['Name'])[0:3]\n",
    "        pair_table_pd[counts_total_cols[4:]] = pair_table_pd[counts_total_cols[4:]].fillna(0).astype(int)\n",
    "        pair_table_pd[counts_total_cols].to_csv(COUNTS_PAIR_SUMMARY_OUTFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PAMs_near_peaks_sides(peaksfile, pamsfile, outfile, left_window=0, right_window=0, \n",
    "                          gene_start_col='start', gene_end_col='end', guide_start_col_num=5):\n",
    "    ''' Finds PAMs near peaks given peaks and PAMs files'''\n",
    "\n",
    "    peaks = pd.read_csv(peaksfile, sep='\\t').sort_values(gene_start_col, ascending=True)\n",
    "    start_peaks_index = list(peaks[gene_start_col])\n",
    "    end_peaks_index = list(peaks[gene_end_col])\n",
    "    pams = open(pamsfile, 'r')\n",
    "    out = open(outfile, 'w')\n",
    "    current_peak = 0\n",
    "    for i, pam in enumerate(pams):\n",
    "        if i == 0:\n",
    "            print(pam.strip('\\n').split(','))\n",
    "            live_write(out, pam.strip('\\n').split(',') + list(peaks.columns))\n",
    "            continue\n",
    "        N = int(pam.split(',')[guide_start_col_num])\n",
    "\n",
    "        while N > end_peaks_index[current_peak]+right_window:\n",
    "            current_peak += 1\n",
    "            if current_peak >= len(end_peaks_index):\n",
    "                break\n",
    "        else:\n",
    "            if (N >= start_peaks_index[current_peak] - left_window) and (N <= end_peaks_index[current_peak] + right_window):\n",
    "                live_write(out, pam.strip('\\n').split(',') + list(peaks.iloc[current_peak]))\n",
    "            continue\n",
    "        break\n",
    "    pams.close()\n",
    "    out.close()\n",
    "\n",
    "    \n",
    "def live_write(out, row):\n",
    "    '''writes row to the end of output table'''\n",
    "    out.write(','.join([str(r) for r in row]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing finding guides for F_Tula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B subtilis file information\n",
    "F_tula_genome = './Ftula_LVS_genomic.fa'\n",
    "F_tula_sites_file = './F_tula_sites.csv'\n",
    "\n",
    "# Find the F tularensis potential binding sites and output sorted by start\n",
    "F_tula_sites = find_guides(read_seq_file(F_tula_genome), 'F_tula')\n",
    "F_tula_sites = F_tula_sites.sort_values('Start')\n",
    "F_tula_sites.to_csv(F_tula_sites_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing genes for B. subtilis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B subtilis file information\n",
    "B_sub_genome = './bsub_genome.gb'\n",
    "B_sub_sites_file = './B_sub_sites.csv'\n",
    "B_sub_gene_file = './B_subtilis_gene_regions.tsv'\n",
    "B_sub_gene_out = './B_subtilis_sites_w_genes.csv'\n",
    "B_sub_essential_file = './B_subtilis_essential_genes.tsv'\n",
    "\n",
    "# Parameters for gene windows\n",
    "left_window = 0\n",
    "right_window = 0\n",
    "gene_start_col='Item_Start'\n",
    "gene_end_col='Item_Stop'\n",
    "\n",
    "# Find the B subtilis potential binding sites and output sorted by start\n",
    "B_sub_sites = find_guides(read_seq_gb(B_sub_genome), 'B_sub')\n",
    "B_sub_sites = B_sub_sites.sort_values('Start')\n",
    "B_sub_sites.to_csv(B_sub_sites_file)\n",
    "\n",
    "# Find the gene information for B subtilis sites\n",
    "PAMs_near_peaks_sides(B_sub_gene_file, B_sub_sites_file, B_sub_gene_out, left_window, right_window, gene_start_col, gene_end_col)\n",
    "B_sub_wgene = pd.read_csv(B_sub_gene_out, index_col=0).drop_duplicates()\n",
    "\n",
    "# Read in the essential gene information\n",
    "B_sub_essential = pd.read_csv(B_sub_essential_file, sep='\\t')\n",
    "\n",
    "# Combine the subtilis sides and gene information\n",
    "B_sub_sites = pd.merge(B_sub_sites, B_sub_wgene, how='left')\n",
    "B_sub_sites_essential = pd.merge(B_sub_sites, B_sub_essential, how='left', left_on='Item_Name', right_on='Name').drop(columns=['Name'])\n",
    "\n",
    "# Save out the B subtilis sites with the gene information\n",
    "B_sub_sites_essential.to_csv(B_sub_gene_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(B_sub_gene_out, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
